# -*- coding: utf-8 -*-
"""MusicGeneratorFINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rEnmJyAOO0V68w0S1OYxiUUUzbBsFv6Z
"""

!pip install kaggle

!unzip Music.zip -d /content/classical_midi

!pip install pretty_midi

import pretty_midi
import numpy as np
from sklearn.preprocessing import LabelBinarizer
midi_files = ['/content/alb_esp1.mid','/content/alb_esp2.mid','/content/alb_esp3.mid','/content/alb_esp4.mid','/content/alb_esp5.mid']

def extract_notes(midi_file):
    midi_data = pretty_midi.PrettyMIDI(midi_file)
    notes = []
    for instrument in midi_data.instruments:
        for note in instrument.notes:
            notes.append((note.pitch, note.start, note.end, note.velocity))
    return notes
all_notes = []

for midi_file in midi_files:
    notes = extract_notes(midi_file)
    all_notes.extend(notes)

pitches = [note[0] for note in all_notes]

sequence_length = 50
sequences = []
next_notes = []
for i in range(len(pitches) - sequence_length):
    sequences.append(pitches[i:i + sequence_length])
    next_notes.append(pitches[i + sequence_length])

unique_notes = sorted(list(set(pitches)))
note_to_int = dict((note, num) for num, note in enumerate(unique_notes))

sequences = np.array([[note_to_int[note] for note in sequence] for sequence in sequences])
next_notes = np.array([note_to_int[note] for note in next_notes])

sequences = np.reshape(sequences, (sequences.shape[0], sequence_length, 1))
sequences = sequences / float(len(unique_notes))
next_notes = LabelBinarizer().fit_transform(next_notes)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

model = Sequential()
model.add(LSTM(256, input_shape=(sequence_length, 1), return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(256))
model.add(Dropout(0.3))
model.add(Dense(len(unique_notes), activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam')
model.fit(sequences, next_notes, epochs=5, batch_size=512)

import random

def generate_midi(predicted_notes, output_file):
    midi_data = pretty_midi.PrettyMIDI()
    instrument = pretty_midi.Instrument(program=0)
    int_to_note = {num: note for note, num in note_to_int.items()}

    for i, pitch in enumerate(predicted_notes):
        note = pretty_midi.Note(
            velocity=100, pitch=int_to_note[pitch], start=i * 0.5, end=(i + 1) * 0.5
        )
        instrument.notes.append(note)

    midi_data.instruments.append(instrument)
    midi_data.write(output_file)

start_sequence = random.choice(sequences)
generated_sequence = list(start_sequence.flatten())
for _ in range(200):
    prediction_input = np.reshape(generated_sequence, (1, len(generated_sequence), 1))
    prediction_input = prediction_input / float(len(unique_notes))

    prediction = model.predict(prediction_input, verbose=0)
    predicted_note = np.argmax(prediction)

    generated_sequence.append(predicted_note)
    generated_sequence = generated_sequence[1:]

generate_midi(generated_sequence, 'generated_music2.mid')

generate_midi(generated_sequence, 'generated_music1.mid')

